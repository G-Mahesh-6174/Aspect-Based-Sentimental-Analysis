{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ba3afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Russia</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>397</td>\n",
       "      <td>1403</td>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>42</td>\n",
       "      <td>1403</td>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>210</td>\n",
       "      <td>1403</td>\n",
       "      <td>Great location in nice surroundings the bar a...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/24/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>140</td>\n",
       "      <td>1403</td>\n",
       "      <td>Amazing location and building Romantic setting</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>\n",
       "      <td>10 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "3   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "4   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score   Hotel_Name  \\\n",
       "0                           194    8/3/2017            7.7  Hotel Arena   \n",
       "1                           194    8/3/2017            7.7  Hotel Arena   \n",
       "2                           194   7/31/2017            7.7  Hotel Arena   \n",
       "3                           194   7/31/2017            7.7  Hotel Arena   \n",
       "4                           194   7/24/2017            7.7  Hotel Arena   \n",
       "\n",
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0              Russia    I am so angry that i made this post available...   \n",
       "1             Ireland                                         No Negative   \n",
       "2           Australia    Rooms are nice but for elderly a bit difficul...   \n",
       "3      United Kingdom    My room was dirty and I was afraid to walk ba...   \n",
       "4         New Zealand    You When I booked with your company on line y...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                397                     1403   \n",
       "1                                  0                     1403   \n",
       "2                                 42                     1403   \n",
       "3                                210                     1403   \n",
       "4                                140                     1403   \n",
       "\n",
       "                                     Positive_Review  \\\n",
       "0   Only the park outside of the hotel was beauti...   \n",
       "1   No real complaints the hotel was great great ...   \n",
       "2   Location was good and staff were ok It is cut...   \n",
       "3   Great location in nice surroundings the bar a...   \n",
       "4    Amazing location and building Romantic setting    \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                 11   \n",
       "1                                105   \n",
       "2                                 21   \n",
       "3                                 26   \n",
       "4                                  8   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           7             2.9   \n",
       "1                                           7             7.5   \n",
       "2                                           9             7.1   \n",
       "3                                           1             3.8   \n",
       "4                                           3             6.7   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "2  [' Leisure trip ', ' Family with young childre...            3 days   \n",
       "3  [' Leisure trip ', ' Solo traveler ', ' Duplex...            3 days   \n",
       "4  [' Leisure trip ', ' Couple ', ' Suite ', ' St...           10 days   \n",
       "\n",
       "         lat       lng  \n",
       "0  52.360576  4.915968  \n",
       "1  52.360576  4.915968  \n",
       "2  52.360576  4.915968  \n",
       "3  52.360576  4.915968  \n",
       "4  52.360576  4.915968  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"Hotel_Reviews.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180fe675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Review\"] = df[\"Negative_Review\"] + df[\"Positive_Review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ff94c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Russia</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>397</td>\n",
       "      <td>1403</td>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>No Negative No real complaints the hotel was g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>42</td>\n",
       "      <td>1403</td>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>210</td>\n",
       "      <td>1403</td>\n",
       "      <td>Great location in nice surroundings the bar a...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/24/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>140</td>\n",
       "      <td>1403</td>\n",
       "      <td>Amazing location and building Romantic setting</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>\n",
       "      <td>10 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "3   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "4   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score   Hotel_Name  \\\n",
       "0                           194    8/3/2017            7.7  Hotel Arena   \n",
       "1                           194    8/3/2017            7.7  Hotel Arena   \n",
       "2                           194   7/31/2017            7.7  Hotel Arena   \n",
       "3                           194   7/31/2017            7.7  Hotel Arena   \n",
       "4                           194   7/24/2017            7.7  Hotel Arena   \n",
       "\n",
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0              Russia    I am so angry that i made this post available...   \n",
       "1             Ireland                                         No Negative   \n",
       "2           Australia    Rooms are nice but for elderly a bit difficul...   \n",
       "3      United Kingdom    My room was dirty and I was afraid to walk ba...   \n",
       "4         New Zealand    You When I booked with your company on line y...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                397                     1403   \n",
       "1                                  0                     1403   \n",
       "2                                 42                     1403   \n",
       "3                                210                     1403   \n",
       "4                                140                     1403   \n",
       "\n",
       "                                     Positive_Review  \\\n",
       "0   Only the park outside of the hotel was beauti...   \n",
       "1   No real complaints the hotel was great great ...   \n",
       "2   Location was good and staff were ok It is cut...   \n",
       "3   Great location in nice surroundings the bar a...   \n",
       "4    Amazing location and building Romantic setting    \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                 11   \n",
       "1                                105   \n",
       "2                                 21   \n",
       "3                                 26   \n",
       "4                                  8   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           7             2.9   \n",
       "1                                           7             7.5   \n",
       "2                                           9             7.1   \n",
       "3                                           1             3.8   \n",
       "4                                           3             6.7   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "2  [' Leisure trip ', ' Family with young childre...            3 days   \n",
       "3  [' Leisure trip ', ' Solo traveler ', ' Duplex...            3 days   \n",
       "4  [' Leisure trip ', ' Couple ', ' Suite ', ' St...           10 days   \n",
       "\n",
       "         lat       lng                                             Review  \n",
       "0  52.360576  4.915968   I am so angry that i made this post available...  \n",
       "1  52.360576  4.915968  No Negative No real complaints the hotel was g...  \n",
       "2  52.360576  4.915968   Rooms are nice but for elderly a bit difficul...  \n",
       "3  52.360576  4.915968   My room was dirty and I was afraid to walk ba...  \n",
       "4  52.360576  4.915968   You When I booked with your company on line y...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fb75f6f-9687-4ec0-b88b-bca02016c143",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5fa134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40ccaee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"y\"] = df[\"Reviewer_Score\"].apply(lambda x: 0 if x < 8.5 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f9c05bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th>Additional_Number_of_Scoring</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Average_Score</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Reviewer_Nationality</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Review_Total_Negative_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Review_Total_Positive_Word_Counts</th>\n",
       "      <th>Total_Number_of_Reviews_Reviewer_Has_Given</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>days_since_review</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>Review</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Russia</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>397</td>\n",
       "      <td>1403</td>\n",
       "      <td>Only the park outside of the hotel was beauti...</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>8/3/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>0</td>\n",
       "      <td>1403</td>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>105</td>\n",
       "      <td>7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Duplex Double...</td>\n",
       "      <td>0 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>No Negative No real complaints the hotel was g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>42</td>\n",
       "      <td>1403</td>\n",
       "      <td>Location was good and staff were ok It is cut...</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>[' Leisure trip ', ' Family with young childre...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/31/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>210</td>\n",
       "      <td>1403</td>\n",
       "      <td>Great location in nice surroundings the bar a...</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[' Leisure trip ', ' Solo traveler ', ' Duplex...</td>\n",
       "      <td>3 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s Gravesandestraat 55 Oost 1092 AA Amsterdam ...</td>\n",
       "      <td>194</td>\n",
       "      <td>7/24/2017</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Hotel Arena</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>140</td>\n",
       "      <td>1403</td>\n",
       "      <td>Amazing location and building Romantic setting</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>[' Leisure trip ', ' Couple ', ' Suite ', ' St...</td>\n",
       "      <td>10 days</td>\n",
       "      <td>52.360576</td>\n",
       "      <td>4.915968</td>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Hotel_Address  \\\n",
       "0   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "1   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "2   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "3   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "4   s Gravesandestraat 55 Oost 1092 AA Amsterdam ...   \n",
       "\n",
       "   Additional_Number_of_Scoring Review_Date  Average_Score   Hotel_Name  \\\n",
       "0                           194    8/3/2017            7.7  Hotel Arena   \n",
       "1                           194    8/3/2017            7.7  Hotel Arena   \n",
       "2                           194   7/31/2017            7.7  Hotel Arena   \n",
       "3                           194   7/31/2017            7.7  Hotel Arena   \n",
       "4                           194   7/24/2017            7.7  Hotel Arena   \n",
       "\n",
       "  Reviewer_Nationality                                    Negative_Review  \\\n",
       "0              Russia    I am so angry that i made this post available...   \n",
       "1             Ireland                                         No Negative   \n",
       "2           Australia    Rooms are nice but for elderly a bit difficul...   \n",
       "3      United Kingdom    My room was dirty and I was afraid to walk ba...   \n",
       "4         New Zealand    You When I booked with your company on line y...   \n",
       "\n",
       "   Review_Total_Negative_Word_Counts  Total_Number_of_Reviews  \\\n",
       "0                                397                     1403   \n",
       "1                                  0                     1403   \n",
       "2                                 42                     1403   \n",
       "3                                210                     1403   \n",
       "4                                140                     1403   \n",
       "\n",
       "                                     Positive_Review  \\\n",
       "0   Only the park outside of the hotel was beauti...   \n",
       "1   No real complaints the hotel was great great ...   \n",
       "2   Location was good and staff were ok It is cut...   \n",
       "3   Great location in nice surroundings the bar a...   \n",
       "4    Amazing location and building Romantic setting    \n",
       "\n",
       "   Review_Total_Positive_Word_Counts  \\\n",
       "0                                 11   \n",
       "1                                105   \n",
       "2                                 21   \n",
       "3                                 26   \n",
       "4                                  8   \n",
       "\n",
       "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
       "0                                           7             2.9   \n",
       "1                                           7             7.5   \n",
       "2                                           9             7.1   \n",
       "3                                           1             3.8   \n",
       "4                                           3             6.7   \n",
       "\n",
       "                                                Tags days_since_review  \\\n",
       "0  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "1  [' Leisure trip ', ' Couple ', ' Duplex Double...            0 days   \n",
       "2  [' Leisure trip ', ' Family with young childre...            3 days   \n",
       "3  [' Leisure trip ', ' Solo traveler ', ' Duplex...            3 days   \n",
       "4  [' Leisure trip ', ' Couple ', ' Suite ', ' St...           10 days   \n",
       "\n",
       "         lat       lng                                             Review  y  \n",
       "0  52.360576  4.915968   I am so angry that i made this post available...  0  \n",
       "1  52.360576  4.915968  No Negative No real complaints the hotel was g...  0  \n",
       "2  52.360576  4.915968   Rooms are nice but for elderly a bit difficul...  0  \n",
       "3  52.360576  4.915968   My room was dirty and I was afraid to walk ba...  0  \n",
       "4  52.360576  4.915968   You When I booked with your company on line y...  0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04400cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No Negative No real complaints the hotel was g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  y\n",
       "0   I am so angry that i made this post available...  0\n",
       "1  No Negative No real complaints the hotel was g...  0\n",
       "2   Rooms are nice but for elderly a bit difficul...  0\n",
       "3   My room was dirty and I was afraid to walk ba...  0\n",
       "4   You When I booked with your company on line y...  0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"Review\", \"y\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5a09d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Review\"] = df[\"Review\"].apply(lambda x: x.replace(\"No Negative\", \"\").replace(\"No Positive\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74690bde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  y\n",
       "0   I am so angry that i made this post available...  0\n",
       "1   No real complaints the hotel was great great ...  0\n",
       "2   Rooms are nice but for elderly a bit difficul...  0\n",
       "3   My room was dirty and I was afraid to walk ba...  0\n",
       "4   You When I booked with your company on line y...  0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb01266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515738\n"
     ]
    }
   ],
   "source": [
    "print((len(df[\"Review\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd938d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df[\"Review\"].replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c56c609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=[\"Review\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6af88652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515611\n"
     ]
    }
   ],
   "source": [
    "print((len(df[\"Review\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "988ce48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_tokenizer(text):\n",
    "    text = text.lower()\n",
    "    text = text.split()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a45e519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "en_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ec13be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in en_stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0613d3e5-eabf-47c9-8090-788369a8a8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mahesh\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "934f7ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "sp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3adeee1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    text = \" \".join(text)\n",
    "    token = sp(text)\n",
    "    text = [word.lemma_ for word in token]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "194775d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x = \"y\", data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f0991cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No real complaints the hotel was great great ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  y\n",
       "0   I am so angry that i made this post available...  0\n",
       "1   No real complaints the hotel was great great ...  0\n",
       "2   Rooms are nice but for elderly a bit difficul...  0\n",
       "3   My room was dirty and I was afraid to walk ba...  0\n",
       "4   You When I booked with your company on line y...  0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "498df786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = text.lower() \n",
    "    text = word_tokenizer(text)\n",
    "    text = lemmatization(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc58babc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 54351/515611 [09:23<1:19:38, 96.52it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      2\u001b[0m tqdm\u001b[38;5;241m.\u001b[39mpandas()\n\u001b[1;32m----> 3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclean_review\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mprogress_map(preprocessing)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:805\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner\u001b[1;34m(df, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;66;03m# Apply the provided function (in **kwargs)\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[38;5;66;03m# on the df using our wrapper (which provides bar updating)\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(df, df_function)(wrapper, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    807\u001b[0m     t\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4397\u001b[0m, in \u001b[0;36mSeries.map\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[0;32m   4319\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4320\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[0;32m   4321\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   4322\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4324\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[0;32m   4325\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4395\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[0;32m   4396\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4397\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_values(arg, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m   4398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4399\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4400\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:924\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    921\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# mapper is a function\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m new_values \u001b[38;5;241m=\u001b[39m map_f(values, mapper)\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:800\u001b[0m, in \u001b[0;36mtqdm.pandas.<locals>.inner_generator.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    795\u001b[0m     \u001b[38;5;66;03m# update tbar correctly\u001b[39;00m\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;66;03m# it seems `pandas apply` calls `func` twice\u001b[39;00m\n\u001b[0;32m    797\u001b[0m     \u001b[38;5;66;03m# on the first column/row to decide whether it can\u001b[39;00m\n\u001b[0;32m    798\u001b[0m     \u001b[38;5;66;03m# take a fast or slow code path; so stop when t.total==t.n\u001b[39;00m\n\u001b[0;32m    799\u001b[0m     t\u001b[38;5;241m.\u001b[39mupdate(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mn \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 800\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m, in \u001b[0;36mpreprocessing\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mlower() \n\u001b[0;32m      3\u001b[0m text \u001b[38;5;241m=\u001b[39m word_tokenizer(text)\n\u001b[1;32m----> 4\u001b[0m text \u001b[38;5;241m=\u001b[39m lemmatization(text)\n\u001b[0;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m remove_stopwords(text)\n\u001b[0;32m      6\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text)\n",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m, in \u001b[0;36mlemmatization\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatization\u001b[39m(text):\n\u001b[0;32m      2\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(text)\n\u001b[1;32m----> 3\u001b[0m     token \u001b[38;5;241m=\u001b[39m sp(text)\n\u001b[0;32m      4\u001b[0m     text \u001b[38;5;241m=\u001b[39m [word\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m token]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\language.py:1049\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m   1047\u001b[0m     error_handler \u001b[38;5;241m=\u001b[39m proc\u001b[38;5;241m.\u001b[39mget_error_handler()\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1049\u001b[0m     doc \u001b[38;5;241m=\u001b[39m proc(doc, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcomponent_cfg\u001b[38;5;241m.\u001b[39mget(name, {}))  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1051\u001b[0m     \u001b[38;5;66;03m# This typically happens if a component is not initialized\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE109\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\trainable_pipe.pyx:52\u001b[0m, in \u001b[0;36mspacy.pipeline.trainable_pipe.TrainablePipe.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:264\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.predict\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:285\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.greedy_parse\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:334\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OutT:\n\u001b[0;32m    331\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\ml\\tb_framework.py:34\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(model, X, is_train):\n\u001b[1;32m---> 34\u001b[0m     step_model \u001b[38;5;241m=\u001b[39m ParserStepModel(\n\u001b[0;32m     35\u001b[0m         X,\n\u001b[0;32m     36\u001b[0m         model\u001b[38;5;241m.\u001b[39mlayers,\n\u001b[0;32m     37\u001b[0m         unseen_classes\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munseen_classes\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     38\u001b[0m         train\u001b[38;5;241m=\u001b[39mis_train,\n\u001b[0;32m     39\u001b[0m         has_upper\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_upper\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     40\u001b[0m     )\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m step_model, step_model\u001b[38;5;241m.\u001b[39mfinish_steps\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\ml\\parser_model.pyx:250\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\with_array.py:42\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, Xseq, is_train)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](Xseq, is_train)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\with_array.py:77\u001b[0m, in \u001b[0;36m_list_forward\u001b[1;34m(model, Xs, is_train)\u001b[0m\n\u001b[0;32m     75\u001b[0m lengths \u001b[38;5;241m=\u001b[39m NUMPY_OPS\u001b[38;5;241m.\u001b[39masarray1i([\u001b[38;5;28mlen\u001b[39m(seq) \u001b[38;5;28;01mfor\u001b[39;00m seq \u001b[38;5;129;01min\u001b[39;00m Xs])\n\u001b[0;32m     76\u001b[0m Xf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(Xs, pad\u001b[38;5;241m=\u001b[39mpad)\n\u001b[1;32m---> 77\u001b[0m Yf, get_dXf \u001b[38;5;241m=\u001b[39m layer(Xf, is_train)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackprop\u001b[39m(dYs: ListXd) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ListXd:\n\u001b[0;32m     80\u001b[0m     dYf \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mflatten(dYs, pad\u001b[38;5;241m=\u001b[39mpad)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\residual.py:41\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m d_output \u001b[38;5;241m+\u001b[39m dX\n\u001b[1;32m---> 41\u001b[0m Y, backprop_layer \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](X, is_train)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [X[i] \u001b[38;5;241m+\u001b[39m Y[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X))], backprop\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "    \u001b[1;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\chain.py:54\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     52\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m---> 54\u001b[0m     Y, inc_layer_grad \u001b[38;5;241m=\u001b[39m layer(X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n\u001b[0;32m     55\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(inc_layer_grad)\n\u001b[0;32m     56\u001b[0m     X \u001b[38;5;241m=\u001b[39m Y\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\model.py:310\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, X, is_train)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, X: InT, is_train: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[OutT, Callable]:\n\u001b[0;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func(\u001b[38;5;28mself\u001b[39m, X, is_train\u001b[38;5;241m=\u001b[39mis_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\layers\\maxout.py:52\u001b[0m, in \u001b[0;36mforward\u001b[1;34m(model, X, is_train)\u001b[0m\n\u001b[0;32m     50\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m W \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape2f(W, nO \u001b[38;5;241m*\u001b[39m nP, nI)\n\u001b[1;32m---> 52\u001b[0m Y \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mgemm(X, W, trans2\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     53\u001b[0m Y \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape1f(b, nO \u001b[38;5;241m*\u001b[39m nP)\n\u001b[0;32m     54\u001b[0m Z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mops\u001b[38;5;241m.\u001b[39mreshape3f(Y, Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], nO, nP)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df['clean_review'] = df['Review'].progress_map(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bb80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('afterpreprossing.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e1185",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df.clean_review.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "df['clean_review2'] = df['clean_review'].progress_map(word_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d02e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c498aef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = df['clean_review2'].values.tolist()\n",
    "len(data_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62660395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.corpora as corpora\n",
    "\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "# Create Corpus\n",
    "texts = data_words\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1][0][:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56634cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import LdaModel\n",
    "from pprint import pprint\n",
    "\n",
    "# number of topics\n",
    "num_topics = 10\n",
    "# Build LDA model\n",
    "lda_model = LdaMulticore(corpus=corpus, id2word=id2word,\n",
    "                     num_topics=num_topics, iterations=400)\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570ea7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from gensim.models import FastText\n",
    "fasttext_model = FastText(data_words, vector_size= 100, window=5, min_count=5, workers=4,sg=1)\n",
    "# fasttext_model = FastText.load_fasttext_format(\"../input/fast100/cc.en.100.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c5b103",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model.save(\"FastText-Model-For-ABSA.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5210a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = [\"food\", \"location\", \"room\", \"service\", \"facility\"]\n",
    "\n",
    "def get_similarity(text, aspect):\n",
    "    try:\n",
    "        text = \" \".join(text)\n",
    "        return fasttext_model.wv.n_similarity(text, aspect)\n",
    "    except:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ae740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "for aspect in aspects:\n",
    "    df[aspect] = df['clean_review2'].progress_map(lambda text: get_similarity(text, aspect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d982a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f963f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Aftersimilarity.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ada7ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Aftersimilarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c6dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import RandomSampler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9ab158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "    IMG_SIZE = (224,224)\n",
    "    DEVICE = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    FOLDS = 5\n",
    "    SHUFFLE = True\n",
    "    BATCH_SIZE = 32\n",
    "    LR = 0.01\n",
    "    EPOCHS = 10\n",
    "    EMB_DIM = 100\n",
    "    MAX_LEN = 20\n",
    "    MODEL_PATH = \"./Models/MyModel.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0531c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "  \n",
    "    '''\n",
    "    __init__ method is called by default as soon as an object of this class is initiated\n",
    "    we use this method to initiate our vocab dictionaries\n",
    "    '''\n",
    "    def __init__(self, freq_threshold, max_size):\n",
    "        '''\n",
    "        freq_threshold : the minimum times a word must occur in corpus to be treated in vocab\n",
    "        max_size : max source vocab size. Eg. if set to 10,000, we pick the top 10,000 most frequent words and discard others\n",
    "        '''\n",
    "        #initiate the index to token dict\n",
    "        ## <PAD> -> padding, used for padding the shorter sentences in a batch to match the length of longest sentence in the batch\n",
    "        ## <SOS> -> start token, added in front of each sentence to signify the start of sentence\n",
    "        ## <EOS> -> End of sentence token, added to the end of each sentence to signify the end of sentence\n",
    "        ## <UNK> -> words which are not found in the vocab are replace by this token\n",
    "        self.itos = {0: '<PAD>', 1:'<SOS>', 2:'<EOS>', 3: '<UNK>'}\n",
    "        #initiate the token to index dict\n",
    "        self.stoi = {k:j for j,k in self.itos.items()} \n",
    "        \n",
    "        self.freq_threshold = freq_threshold\n",
    "        self.max_size = max_size\n",
    "    \n",
    "    '''\n",
    "    __len__ is used by dataloader later to create batches\n",
    "    '''\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    '''\n",
    "    a simple tokenizer to split on space and converts the sentence to list of words\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def tokenizer(text):\n",
    "        return [tok.lower().strip() for tok in text.split(' ')]\n",
    "    \n",
    "    '''\n",
    "    build the vocab: create a dictionary mapping of index to string (itos) and string to index (stoi)\n",
    "    output ex. for stoi -> {'the':5, 'a':6, 'an':7}\n",
    "    '''\n",
    "    def build_vocabulary(self, sentence_list):\n",
    "        #calculate the frequencies of each word first to remove the words with freq < freq_threshold\n",
    "        frequencies = {}  #init the freq dict\n",
    "        idx = 4 #index from which we want our dict to start. We already used 4 indexes for pad, start, end, unk\n",
    "        \n",
    "        #calculate freq of words\n",
    "        for sentence in sentence_list:\n",
    "            for word in self.tokenizer(sentence):\n",
    "                if word not in frequencies.keys():\n",
    "                    frequencies[word]=1\n",
    "                else:\n",
    "                    frequencies[word]+=1\n",
    "                    \n",
    "                    \n",
    "        #limit vocab by removing low freq words\n",
    "        frequencies = {k:v for k,v in frequencies.items() if v>self.freq_threshold} \n",
    "        \n",
    "        #limit vocab to the max_size specified\n",
    "        frequencies = dict(sorted(frequencies.items(), key = lambda x: -x[1])[:self.max_size-idx]) # idx =4 for pad, start, end , unk\n",
    "            \n",
    "        #create vocab\n",
    "        for word in frequencies.keys():\n",
    "            self.stoi[word] = idx\n",
    "            self.itos[idx] = word\n",
    "            idx+=1\n",
    "            \n",
    "     \n",
    "    '''\n",
    "    convert the list of words to a list of corresponding indexes\n",
    "    '''    \n",
    "    def numericalize(self, text):\n",
    "        #tokenize text\n",
    "        tokenized_text = self.tokenizer(text)\n",
    "        numericalized_text = []\n",
    "        for token in tokenized_text:\n",
    "            if token in self.stoi.keys():\n",
    "                numericalized_text.append(self.stoi[token])\n",
    "            else: #out-of-vocab words are represented by UNK token index\n",
    "                numericalized_text.append(self.stoi['<UNK>'])\n",
    "                \n",
    "        return numericalized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce2fe25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    '''\n",
    "    Initiating Variables\n",
    "    df: the training dataframe\n",
    "    source_column : the name of source text column in the dataframe\n",
    "    transform : If we want to add any augmentation\n",
    "    freq_threshold : the minimum times a word must occur in corpus to be treated in vocab\n",
    "    source_vocab_max_size : max source vocab size\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, df, source_column,freq_threshold = 3,\n",
    "                source_vocab_max_size = 10000 , transform=None):\n",
    "    \n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "        #get source and target texts\n",
    "        self.source_texts = self.df[source_column]\n",
    "        \n",
    "        \n",
    "        ##VOCAB class has been created above\n",
    "        #Initialize source vocab object and build vocabulary\n",
    "        self.source_vocab = Vocabulary(freq_threshold, source_vocab_max_size)\n",
    "        self.source_vocab.build_vocabulary(self.source_texts.tolist())\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    '''\n",
    "    __getitem__ runs on 1 example at a time. Here, we get an example at index and return its numericalize source and\n",
    "    target values using the vocabulary objects we created in __init__\n",
    "    '''\n",
    "    def __getitem__(self, index):\n",
    "        source_text = self.source_texts[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            source_text = self.transform(source_text)\n",
    "            \n",
    "        #numericalize texts ['<SOS>','cat', 'in', 'a', 'bag','<EOS>'] -> [1,12,2,9,24,2]\n",
    "        numerialized_source = [self.source_vocab.stoi[\"<SOS>\"]]\n",
    "        numerialized_source += self.source_vocab.numericalize(source_text)\n",
    "        numerialized_source.append(self.source_vocab.stoi[\"<EOS>\"])\n",
    "        \n",
    "        #convert the list to tensor and return\n",
    "        return torch.tensor(numerialized_source), torch.tensor(self.df.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff1d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(df, \"clean_review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f2c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.source_vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32a89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('dataset-new', 'wb') as dataset_file:\n",
    " \n",
    "  # Step 3\n",
    "    pickle.dump(dataset, dataset_file, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# import pickle\n",
    " \n",
    "# # Step 2\n",
    "# with open('./dataset', 'rb') as config_dictionary_file:\n",
    " \n",
    "#     # Step 3\n",
    "#     config_dictionary = pickle.load(config_dictionary_file)\n",
    " \n",
    "#     # After config_dictionary is read from file\n",
    "#     print(config_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ffb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_layer_with_weights(target_vocab, emb_model, trainable = False):\n",
    "\n",
    "    weights_matrix = np.zeros((len(target_vocab), config.EMB_DIM))\n",
    "    words_found = 0\n",
    "    \n",
    "    for i, word in enumerate(target_vocab):\n",
    "        weights_matrix[i] = np.concatenate([emb_model.wv[word]])\n",
    "        words_found += 1\n",
    "                \n",
    "    print(f\"Words found are : {words_found}\")\n",
    "    \n",
    "    weights_matrix = torch.tensor(weights_matrix, dtype = torch.float32).reshape(len(target_vocab), config.EMB_DIM)\n",
    "    emb_layer = nn.Embedding.from_pretrained(weights_matrix)\n",
    "    print(emb_layer)\n",
    "    if trainable:\n",
    "        emb_layer.weight.requires_grad = True\n",
    "    else:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCollate:\n",
    "    def __init__(self, pad_idx, maxlen):\n",
    "        self.pad_idx = pad_idx\n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "    \n",
    "    #__call__: a default method\n",
    "    ##   First the obj is created using MyCollate(pad_idx) in data loader\n",
    "    ##   Then if obj(batch) is called -> __call__ runs by default\n",
    "    def __call__(self, batch):\n",
    "        #get all source indexed sentences of the batch\n",
    "        source = [item[0] for item in batch] \n",
    "        #pad them using pad_sequence method from pytorch. \n",
    "#         source = pad_sequence(source, batch_first=False, padding_value = self.pad_idx)\n",
    "        \n",
    "        padded_sequence = torch.zeros((self.maxlen, len(batch)), dtype = torch.int)\n",
    "        \n",
    "        for idx, text in enumerate(source):\n",
    "            \n",
    "            if len(text) > self.maxlen:\n",
    "                padded_sequence[:, idx] = source[idx][: self.maxlen]\n",
    "            else:\n",
    "                padded_sequence[:len(source[idx]), idx] = padded_sequence[:len(source[idx]), idx] + source[idx]\n",
    "                \n",
    "        \n",
    "        #get all target indexed sentences of the batch\n",
    "        target = [item[1] for item in batch] \n",
    "        \n",
    "        target = torch.tensor(target, dtype = torch.float32).reshape(-1)\n",
    "        return padded_sequence, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ab4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, embedding_layer):\n",
    "        super().__init__()\n",
    "#         self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional = True)\n",
    "        self.fc1 = nn.Linear(2*hidden_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, output_dim)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        max_len, N = text.shape\n",
    "        hidden = torch.zeros((2, N , self.hidden_dim),\n",
    "                          dtype=torch.float)\n",
    "        memory = torch.zeros((2, N , self.hidden_dim),\n",
    "                          dtype=torch.float)\n",
    "        hidden = hidden.to(config.DEVICE)\n",
    "        memory = memory.to(config.DEVICE)\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.lstm(embedded, (hidden, memory))\n",
    "#         assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        y_pred = output[-1,:,:]\n",
    "        y_pred = self.fc1(y_pred)\n",
    "        y_pred = self.fc2(y_pred)\n",
    "        y_pred = self.sigmoid(y_pred)\n",
    "                         \n",
    "        return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epochs(dataloader,model, loss_fn, optimizer):\n",
    "    train_correct = 0\n",
    "    train_loss = 0\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for review, label in tqdm(dataloader):\n",
    "        \n",
    "        review, label = review.to(config.DEVICE), label.to(config.DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(review)\n",
    "        output = output.reshape(-1)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()*review.size(1)\n",
    "        prediction = (output > 0.5).float()\n",
    "        train_correct += (prediction == label).float().sum()\n",
    "        \n",
    "    return train_loss, train_correct\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135681b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_epochs(dataloader, model, loss_fn):\n",
    "    val_correct = 0\n",
    "    val_loss = 0\n",
    "    \n",
    "    model.eval()\n",
    "#     hidden = model.init_hidden(config.BATCH_SIZE)\n",
    "\n",
    "    for review, label in dataloader:\n",
    "        \n",
    "        review, label = review.to(config.DEVICE), label.to(config.DEVICE)\n",
    "        \n",
    "        output = model(review)\n",
    "        output = output.reshape(-1)\n",
    "\n",
    "        loss = loss_fn(output, label)\n",
    "        \n",
    "        val_loss += loss.item()*review.size(1)\n",
    "        prediction = (output > 0.5).float()\n",
    "        val_correct += (prediction == label).float().sum()\n",
    "#         prediction = \n",
    "    return val_loss, val_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a599530",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# sfk = StratifiedKFold(n_splits = config.FOLDS)\n",
    "kfold = KFold(n_splits = config.FOLDS)\n",
    "model_state_dicts = {}\n",
    " \n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(np.arange(len(dataset)))):\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    val_sampler = SubsetRandomSampler(val_idx)\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size = config.BATCH_SIZE, sampler = train_sampler, collate_fn = MyCollate(0, config.MAX_LEN))\n",
    "    val_loader = DataLoader(dataset, batch_size = config.BATCH_SIZE, sampler = val_sampler, collate_fn = MyCollate(0, config.MAX_LEN))  \n",
    "    \n",
    "    VOCAB_SIZE = len(dataset.source_vocab)\n",
    "    HIDDEN_DIM = 128\n",
    "    OUTPUT_DIM = 1\n",
    "    VOCAB = list(dataset.source_vocab.stoi)\n",
    "\n",
    "    embedding_layer = get_emb_layer_with_weights(target_vocab = VOCAB, emb_model = fasttext_model, trainable = False)\n",
    "\n",
    "    model = Model(VOCAB_SIZE, config.EMB_DIM, HIDDEN_DIM, OUTPUT_DIM, embedding_layer)\n",
    "    model = model.to(config.DEVICE)\n",
    "    \n",
    "#     model\n",
    "#     model = Model(2, len(dataset.source_vocab), 128, 100, 1 ).to(config.DEVICE)\n",
    "#     hidden = model.init_hidden(config.BATCH_SIZE)\n",
    "#     model.hidden = hidden\n",
    "\n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr = 0.1)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    print(f\"-----------------------------------------------------------{fold}-fold of the model-----------------------------------------------------------\")\n",
    "    for epoch in range(config.EPOCHS):\n",
    "        train_loss, train_correct = train_epochs(train_loader, model, loss_fn, optimizer)\n",
    "        val_loss, val_correct = val_epochs(val_loader, model, loss_fn)  \n",
    "        \n",
    "        train_loss = train_loss/len(train_loader.sampler)\n",
    "        val_loss = val_loss/len(val_loader.sampler)\n",
    "        train_acc = (train_correct/len(train_loader.sampler))*100\n",
    "        val_acc = (val_correct/len(val_loader.sampler))*100\n",
    "        \n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc.cpu().numpy().tolist())\n",
    "        val_accs.append(val_acc.cpu().numpy().tolist())\n",
    "        \n",
    "        print(f\"| Train Loss : {train_loss} |\", end = \" \")\n",
    "        print(f\" Val Loss : {val_loss} |\", end = \" \")\n",
    "        print(f\"Train Acc : {train_acc} |\", end = \" \")\n",
    "        print(f\"Val Acc : {val_acc} |\")\n",
    "\n",
    "        \n",
    "    # Saving the state dicts for the model\n",
    "    model_state_dicts.update({f\"LSTM-Model-for-{fold}\" : model.state_dict(),\n",
    "                             f\"Model-Optimizer-for-{fold}\" : optimizer.state_dict()})\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.plot(train_accs)\n",
    "    plt.plot(val_accs)\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(train_losses)\n",
    "    plt.plot(val_losses)\n",
    "    plt.title('Model Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_state_dicts, \"My-Model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize(text):\n",
    "    \n",
    "    numerialized_source = [] \n",
    "    numerialized_source = [dataset.source_vocab.stoi[\"<SOS>\"]]\n",
    "    numerialized_source += dataset.source_vocab.numericalize(text)\n",
    "    numerialized_source.append(dataset.source_vocab.stoi[\"<EOS>\"])\n",
    "    \n",
    "    return numerialized_source\n",
    "\n",
    "def padding(source):\n",
    "    padded_sequence = torch.zeros(config.MAX_LEN, 1, dtype = torch.int)\n",
    "    source = torch.tensor(source)\n",
    "    \n",
    "    if len(source) > config.MAX_LEN:\n",
    "        padded_sequence[:, 0] = source[: config.MAX_LEN]\n",
    "    else:\n",
    "        padded_sequence[:len(source), 0] = padded_sequence[:len(source), 0] + source\n",
    "    \n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509d7798",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_processing(text):\n",
    "    \n",
    "    text = preprocessing(text)\n",
    "    text = numericalize(text)\n",
    "    text = padding(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7811299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspects = [\"food\", \"location\", \"room\", \"service\", \"facility\"]\n",
    "\n",
    "def get_similarity(text, aspect):\n",
    "    try:\n",
    "#         text = \" \".join(text)\n",
    "        return fasttext_model.wv.n_similarity(text, aspect)\n",
    "    except:\n",
    "        return 0\n",
    "    \n",
    "def best_aspect(text, aspects):\n",
    "    a = []\n",
    "    \n",
    "    for aspect in aspects:\n",
    "        a.append(get_similarity(text, aspect))\n",
    "    \n",
    "    return aspects[np.argmax(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a1c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"place is not good\"\n",
    "\n",
    "ba = best_aspect(preprocessing(sample), aspects)\n",
    "\n",
    "a = infer_processing(sample).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68649a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sentiment = model(a)\n",
    "sentiment = sentiment.cpu().detach().numpy()[0]\n",
    "print(sentiment)\n",
    "if sentiment > 0.5:\n",
    "    sentiment = 'Positively'\n",
    "else :\n",
    "    sentiment = 'Negatively'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf3d549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"The reviewer is talking {sentiment} about the {ba} aspect in his/her review\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
